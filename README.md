# Understanding the Rentvision-Media-DL-Editor
## Introduction

Welcome to the main page of the `rentvision-media-dl-editor` repository! This was a project developed by Jeevan Rajagopal (writer of this README) during an internship project sponsored by [RentVision](https://www.rentvision.com) spanning through most of 2020. I hope that this README will inform you of the general details surrounding this project.

## Purpose and Motivation

The [RentVision](https://www.rentvision.com) Media Team is tasked with creating visual content that ultimately forms the main product of their company. As such, it was imperative that their workflow was done as efficiently as possible, to ensure that the team could continue to meet scaling demands in the future.

Although the team had developed scripts to achieve this, there were many issues regarding stability, maintainability, and robustness which lead to the formation of this project where the goal was to rennovate the existing code.

My personal motivations, however, extend slightly beyond the presented task. My goal was to create a framework that not only met the functionality requirements, but also did so in a way that was as user and developer-friendly as I could make it within the time I was allotted. Many of my design decisions are impacted by a perceived need to have code that is easily understood and accessible to a wide variety of individuals.

Thus, though the framework developed is tuned for the original purpose, should be general enough that it could be applied to any number of projects where some sort of automatic pipeline system would be beneficial.

---

## What the Expectations Were

To give an idea of why certain design decisions were made (good or bad), it helps to have an understanding of what this project was **expected to do**. As such, below is an bulleted list of those expectations.

- Given a media submission, apply the proper transformations to said media
- Track which users submitted what submission, and notify them at critical steps in the process
- Allow for new users to be added to the pipeline
- Media that is processed must be automatically uploaded to different media hosting websites
- Allow for users to perform ad-hoc querying of pipline and receive real-time information.
- Allow for the use of submission-specific "media profiles" generated by users
- Must be able to handle multi-file media
- Must have handling for submissions with different initial processing states
- Must have user-friendly configuration files that are used when compiling pipeline
- Must have ability to automatically move important metadata to internal database(s)
- Log pipline performance for easy debugging by future maintainers
- Ensure documentation is available in multiple forms and is accessible to target audience

Now while this list is not an exhaustive list, it does cover the major features that were described by the client themselves. To give a very succinct version of the requirements, **the end product must do everything the original did and more**.

My expectations are a little different. As the **sole** developer for the project, I had to include a couple additional points to ensure that the project would succeed both short-term and long after I had left.

- Ensure that all code that constitutes the project is representative of current coding capabilities in professional environment
- Ensure that all client requests are well-understood by both parties, including potential pitfalls and unintended consequences of enacting said requests
- Create reasonably comprehensive technical documentation that, if used by entities unfamiliar with the inner workings of the project, would provide enough information for design decisions to be understood.
- Create easy-to-access "plain English" documentation that would assist non-developers in understanding an abstracted version of the project.

Though I as the developer know this project quite intimately, I hope that you, the reader, will be able to judge whether these expectations were met.

---

## How to Run the Pipeline
### Required Environment
Before this pipeline can be used, there are a few things that must be present in your computer (termed 'environment') such that it works as intended. They are listed (unordered) as follows:

- Linux-based OS (Project was housed on Ubuntu 18.04)
- Python 3.8 or greater

Since this project was developed specifically inside of a Linux environment, there are certain Python idiosyncracies that are necessary for the pipeline to run as originally intended. These idiosyncracies are largely due to the nature of the Python `multiprocessing` package, so if you intend to port this to a different OS and encounter errors, be sure to start from that package.

Additionally, there are several packages that must be present for the pipeline to work as intended. However, that likely exceeds the scope of this document, thus it will be omitted. 

As the developer, I personally recommend the use of 'virtual environment' tools, such as **venv** or **Anaconda** to help manage different environments (and avoid catastrophic failure). A *requirements.txt* may be found within the repository to replicate the working environment for this pipeline.

As an aside, **make sure that you differentiate between Python 2.7 and Python 3.x** as this may cause errors that would otherwise not exist due to version differences. This can be checked by running `python --version` and, if that returns Python 2.7, `python3 --version`.  

This guide assumes that python3 will point to Python 3.8, and therefore will be used for any commands involving it.

---

### Running the Deep Learning Pipeline
Running the Deep Learning Pipeline is relatively straightforward. The main driver program for this section is titled `manage_pipelines.py`. For first-time users, run the following command:

     python3 manage_pipelines.py --help 

to get a description of what the program does, along with the flags needed. In the case of `manage_pipelines.py`, the directory flag, marked `-d`, is an absolute file path that stops at the directory two steps above all user directories.

The reason for this, is that due to the file structure at the time of development, input and output files were one step above the user directories, resulting in a file path that looked akin to this: 

    path/to/directories/.../users/input|output/initials/

If you intend to make use of this project, it is likely in your best interest to build your own driver function(s) to move data into the pipeline, as this driver function is somewhat specialized for this purpose.

---

## How You Could Help Improve This
If, for whatever reason, you find that this project is of great interest to you and feel convinced that there are things that you can do to refine this project furhter, then below are a few things I am currently slating as "future work".

### Shifting PipelineManager to have asynchronous functionality
Currently the entire pipeline currently runs in a sequential or synchronous fashion. While this has some benefits unto its own, there are still issues with handling new submissions that come in at random. 

Furthermore, submissions are buffered if the pipeline is already running, meaning any new submissions must wait until the entire pipeline is finished, despite more than half of the pipeline being inactive at any given time.

To address this, shifting the paradigm of the PipelineManager to an "asynchronous" fashion would mean that, at any given time, submissions can be immediately processed upon arrival. 

However, this would require major overhauls to the system, as the multiprocessing system that forms the PipelineManager was not designed with asynchronous behavior in mind. This is especially apparent in inter-PipelineManager communication, as there may be potential issues in transforming Queue structures into asynchronous-friendly structures.

---

### Type Annotation/Type Hinting and Unit Testing
As of now, the pipeline system works, but has a significant lack of any unit tests and annotations. Currently only basic Type Hints are in place, to allow future developers to have a better understanding of the types that variables are expected to be at various points in the code, similar to how strongly typed languages (e.g., Java, C++) exist by default. 

Unit testing, however, remains an issue. While there are some basic tests that cover some of the earliest aspects of the pipeline, the coverage remains abysmal.

---

# Project Results and Closing Remarks
As my time at [RentVision](https://www.rentvision.com) comes to a close, so to does the current cycle of development for this project. I feel that, overall, the project successfully met all established requirements, including my own. Furthermore, it is not simply a successful internship project, this project is estimated to have saved roughly ***$30,000 per year*** in Media Team operational costs and has ensured that the company had scalability in performing more remote work for content creation.